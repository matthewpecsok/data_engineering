{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMwFAZvwmzPBK1+wJ9M74Pn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewpecsok/data_engineering/blob/main/tutorials/de_building_flat_files_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building flat files tutorial\n",
        "\n",
        "In this tutorial we'll review some useful shell commands that can be run as magics in Jupyter notebooks. We'll then begin building example dataframes in pandas to illustrate how to write CSV, Parquet as well as AVRO format."
      ],
      "metadata": {
        "id": "RtCx2_ZIe9B6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shell commands (as magics)"
      ],
      "metadata": {
        "id": "9nChKLC2fTK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "what directory are we currently in? Using the 'print working directory' command aka pwd. Prefixing the ! tells jupyter this is a shell magic command, not python code."
      ],
      "metadata": {
        "id": "WXd40j_RfX7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pwd"
      ],
      "metadata": {
        "id": "lLG-hdA2h6Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "56NSpvP_XENu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "show the contents of the working directory. For now it's just another directory."
      ],
      "metadata": {
        "id": "EdnE2uHQfp7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ls"
      ],
      "metadata": {
        "id": "CNTLXcKth7Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "UFdYz2NyUdZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make a new directory named some_dir"
      ],
      "metadata": {
        "id": "0BoKV5TLfvh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mkdir"
      ],
      "metadata": {
        "id": "7nkcQXvUh8Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir some_dir"
      ],
      "metadata": {
        "id": "-06Xmm1HXHJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ls again to see the new directory"
      ],
      "metadata": {
        "id": "DvMMg5iRfzPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "k1pQEreJXJKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "change the current working directory to our new directory."
      ],
      "metadata": {
        "id": "8l_JpM_Mf10v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd some_dir"
      ],
      "metadata": {
        "id": "Gg2dB0pLXKQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check our working directory"
      ],
      "metadata": {
        "id": "X9Qn4gqQf59W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "-s3hTDcXXMNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create a new file with the touch command. It will be an empty text file."
      ],
      "metadata": {
        "id": "Qih7TxH0f8zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### touch"
      ],
      "metadata": {
        "id": "63G3LukQh3vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch somefile.txt"
      ],
      "metadata": {
        "id": "_6gWkvj1XeiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "list our new directory to see the file created. use an \"argument\" to give more detail. this creates a \"long\" listing (the l argument) with human readable output for the file size (the h argument) showing the file size is 0k, or empty.\n",
        "We also get the timestamp on the file and the file permissions.\n",
        "\n",
        "This file is readable/writable by the owner, readable by the group and readable by everyone."
      ],
      "metadata": {
        "id": "9PKmckFpgCwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### command arguments"
      ],
      "metadata": {
        "id": "6mGxe0OEh2EW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "metadata": {
        "id": "F3HdBCMmXhIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### echo"
      ],
      "metadata": {
        "id": "dm_QHiTkhyql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the echo command can print to screen something you say, or print the same text to a file. The >> determines if the command will overwrite the file or append."
      ],
      "metadata": {
        "id": "YXV1GLlZhl-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo 'hello world!'"
      ],
      "metadata": {
        "id": "6z_8bc8ziMX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"hi matt!\" > somefile.txt ## > overwrite"
      ],
      "metadata": {
        "id": "MJSb7z3cXy_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the cat command can print out the data in a file. be warned if the file is large, this command is a poor choice!"
      ],
      "metadata": {
        "id": "N_9WxeRfiE5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat somefile.txt"
      ],
      "metadata": {
        "id": "7aRA0RkaX26j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"more text!\" >> somefile.txt ## > append"
      ],
      "metadata": {
        "id": "02MX0kMeiYL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat somefile.txt"
      ],
      "metadata": {
        "id": "4as8rEVaicop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cat on the os-release file tells us what operating system we are using in Colab."
      ],
      "metadata": {
        "id": "y0YtobMYiqDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /etc/os-release"
      ],
      "metadata": {
        "id": "a4cN6EXWX7wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a CSV from scratch with shell commands\n",
        "\n",
        "we'll use jupyter magics to execute unix shell commands to create a simple csv file on our filesystem and then import it with pandas"
      ],
      "metadata": {
        "id": "AfsrU05eL1fz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luGcTd6XJhoh"
      },
      "outputs": [],
      "source": [
        "%ls -l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch mycsv.csv"
      ],
      "metadata": {
        "id": "Ja-dGwygJone"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -lh"
      ],
      "metadata": {
        "id": "483Q6toKKPFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"Company,Email,Phone Number,TotalSales\" > mycsv.csv\n",
        "!echo \"Company A,email@companya.com,888-555-3333,98.12\" >> mycsv.csv\n",
        "!echo \"Company B,email@companyb.com,444-555-1234,123.45\" >> mycsv.csv\n",
        "!echo \"Company C,email@companyc.com,987-123-4855,65.64\" >> mycsv.csv\n",
        "!echo \"Company D,email@companyd.com,987-125-9542,49.18\" >> mycsv.csv\n",
        "!echo \"Company E,email@companyd.com,987-634-4687,44.38\" >> mycsv.csv"
      ],
      "metadata": {
        "id": "1kD9-0u5KWri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat mycsv.csv"
      ],
      "metadata": {
        "id": "vbnVz4GoK4Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import the pandas package so we can deserialize the file."
      ],
      "metadata": {
        "id": "Om_bJRPwjSe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "92u6bY82KxTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
      ],
      "metadata": {
        "id": "x2gUvBdEasKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_csv = pd.read_csv('mycsv.csv')\n",
        "my_csv"
      ],
      "metadata": {
        "id": "20dytgz5LueD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### shape"
      ],
      "metadata": {
        "id": "zv-Xz-qkkRNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_csv.shape"
      ],
      "metadata": {
        "id": "uLPrhbkZjlSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### info"
      ],
      "metadata": {
        "id": "eUebzjvHqRk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_csv.info()"
      ],
      "metadata": {
        "id": "Q4wi7Q26qSrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### describe"
      ],
      "metadata": {
        "id": "H1BeC0_AkUIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_csv.describe(include='all')"
      ],
      "metadata": {
        "id": "9xOPdhSTkJs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### head"
      ],
      "metadata": {
        "id": "BA6feOD9kcwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_csv.head(n=2)"
      ],
      "metadata": {
        "id": "FgqdF95bkeV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tail"
      ],
      "metadata": {
        "id": "yvxFFiakkjR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_csv.tail(n=2)"
      ],
      "metadata": {
        "id": "TX8RSAgzkk1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cp\n",
        "\n",
        "the cp shell command makes a copy of a file."
      ],
      "metadata": {
        "id": "tidEfYluknq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp mycsv.csv anewcsv.csv"
      ],
      "metadata": {
        "id": "eHmNWV5iLwTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -l"
      ],
      "metadata": {
        "id": "MBEuYiAoSrRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### rm\n",
        "\n",
        "removes a file or files."
      ],
      "metadata": {
        "id": "ss00TfiwkwW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm anewcsv.csv"
      ],
      "metadata": {
        "id": "CRM6VonzSvy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -l"
      ],
      "metadata": {
        "id": "A95gPuwiSzIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Faker"
      ],
      "metadata": {
        "id": "iWKNLT4ak6pZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "faker is a useful python package to generate synthetic data that can look like real data. it uses randomization to pull from a list of data internally to mock new data. there is not an infinite quantity of names, but it's still quite useful when prototyping for an upcoming project that you have no data for."
      ],
      "metadata": {
        "id": "288yz0Dkk-em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "id": "MNFC5eVuTkoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "fake=Faker()"
      ],
      "metadata": {
        "id": "KRIY-5wZSz_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake.name()"
      ],
      "metadata": {
        "id": "vUgyKuCKlL6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake.name()"
      ],
      "metadata": {
        "id": "TIV9P0bzlMuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake.name()"
      ],
      "metadata": {
        "id": "jcl_dHkjlNs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake.random_int(min=10, max=60, step=1)"
      ],
      "metadata": {
        "id": "D75Ob76DljdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake.random_int(min=10, max=60, step=1)"
      ],
      "metadata": {
        "id": "qsyIIovslo6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake.random_int(min=10, max=60, step=10)"
      ],
      "metadata": {
        "id": "ZrJjhrWHl1Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake.random_int(min=10, max=60, step=10)"
      ],
      "metadata": {
        "id": "PlSLf5gHl-Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate a list of dictionaries. for illustration purposes keep the list of dicts small, then scale it up to generate more data."
      ],
      "metadata": {
        "id": "b9G4CRzQmFB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate 2 records"
      ],
      "metadata": {
        "id": "LH8AxOTfmjw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_data_list = list()\n",
        "\n",
        "for x in range(2):\n",
        "\n",
        "  data={\"name\":fake.name(),\n",
        "        \"age\":fake.random_int(min=10, max=60, step=1),\n",
        "        \"street\":fake.street_address(),\n",
        "        \"city\":fake.city(),\"state\":fake.state(),\n",
        "        \"zip\":fake.zipcode(),\n",
        "        \"lng\":float(fake.longitude()),\n",
        "        \"lat\":float(fake.latitude())}\n",
        "\n",
        "  our_fake_data_list.append(data)\n",
        "\n",
        "our_fake_data_list"
      ],
      "metadata": {
        "id": "x5Ir3NNYmQrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate 1000 records"
      ],
      "metadata": {
        "id": "q0GUnbnvmmZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_data_list = list()\n",
        "type(our_fake_data_list)\n",
        "\n",
        "for x in range(1000):\n",
        "\n",
        "  data={\"name\":fake.name(),\n",
        "        \"age\":fake.random_int(min=10, max=60, step=1),\n",
        "        \"street\":fake.street_address(),\n",
        "        \"city\":fake.city(),\"state\":fake.state(),\n",
        "        \"zip\":fake.zipcode(),\n",
        "        \"lng\":float(fake.longitude()),\n",
        "        \"lat\":float(fake.latitude())}\n",
        "\n",
        "  our_fake_data_list.append(data)"
      ],
      "metadata": {
        "id": "Ma_fMMc3TjKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_df = pd.DataFrame.from_records(our_fake_data_list)"
      ],
      "metadata": {
        "id": "1cgCCoSSVX8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_df.shape"
      ],
      "metadata": {
        "id": "KN4FzbJoTw6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_df.head()"
      ],
      "metadata": {
        "id": "QSmqkyPvXhuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "serialize our file to a CSV. what type of encoding does this use by default? Look at the help text to see."
      ],
      "metadata": {
        "id": "vLZ477Brm7QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_df.to_csv('fake_csv.csv',index=False)"
      ],
      "metadata": {
        "id": "U0S85bvNT5qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -lh"
      ],
      "metadata": {
        "id": "D441sM1YXWyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_three_rows = pd.read_csv('fake_csv.csv',nrows=3)"
      ],
      "metadata": {
        "id": "QC7Y3D8yXYJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_three_rows.shape"
      ],
      "metadata": {
        "id": "st6_eppHZfEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_df.to_csv('fake_csv_utf_16.csv',index=False,encoding='UTF-16')\n",
        "our_fake_df.to_csv('fake_csv_utf_32.csv',index=False,encoding='UTF-32')"
      ],
      "metadata": {
        "id": "IOs6y9mznKaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -lh"
      ],
      "metadata": {
        "id": "0ytLDtNonRCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compression, CSV files, Parquet files and AVRO\n",
        "\n",
        "Comparing the file size for compression, and limitations.  "
      ],
      "metadata": {
        "id": "tWv6gC4QekEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_data_list = list()\n",
        "type(our_fake_data_list)\n",
        "\n",
        "for x in range(1000):\n",
        "\n",
        "  data={\"name\":fake.name(),\n",
        "        \"Customer\":fake.random_element(elements=('Yes','No')),\n",
        "        \"Status\":fake.random_element(elements=('Active','Inactive'))}\n",
        "\n",
        "  our_fake_data_list.append(data)\n",
        "  our_fake_df = pd.DataFrame.from_records(our_fake_data_list)\n",
        "\n",
        "our_fake_df"
      ],
      "metadata": {
        "id": "lUR_IND2Zgc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSV and Parquet\n",
        "\n",
        "Pay close attention to the file size comparing the CSV to Parquet."
      ],
      "metadata": {
        "id": "jyK4-7zXoAcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_df.to_csv('compression_csv.csv',index=False)\n",
        "our_fake_df.to_parquet('compression_parquet.parquet',index=False)"
      ],
      "metadata": {
        "id": "-RhDD9T0e12v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -lh"
      ],
      "metadata": {
        "id": "Qu-x1bHagYHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_data_list = list()\n",
        "type(our_fake_data_list)\n",
        "\n",
        "for x in range(1000):\n",
        "\n",
        "  data={\"name\":fake.name(),\n",
        "        \"Customer\":fake.lexify('???')}\n",
        "\n",
        "  our_fake_data_list.append(data)\n",
        "  our_fake_df = pd.DataFrame.from_records(our_fake_data_list)\n",
        "\n",
        "our_fake_df.to_csv('random_letters_compression_csv.csv',index=False)\n",
        "our_fake_df.to_parquet('random_letters_compression_parquet.parquet',index=False)"
      ],
      "metadata": {
        "id": "J8QU9urFgZg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_df"
      ],
      "metadata": {
        "id": "7IvqDt2ihLEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_df.Customer.nunique() # almost all unique values"
      ],
      "metadata": {
        "id": "9tNZAMYFZ5iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_fake_df.name.nunique() # almost all unique values"
      ],
      "metadata": {
        "id": "NiHxGCM4afz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -lh"
      ],
      "metadata": {
        "id": "RyU_HoIyg-7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wait what? I thought you said it used compression!!!! Why is the random_letters_compression Parquet file larger than the CSV?"
      ],
      "metadata": {
        "id": "DiUfVcxyiXwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AVRO"
      ],
      "metadata": {
        "id": "QDPY5iwke5mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastavro"
      ],
      "metadata": {
        "id": "VlAmxbAa0GHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastavro import writer, reader, parse_schema"
      ],
      "metadata": {
        "id": "Nu0Wkf9lg_Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = {\n",
        "    'doc': 'fake test',\n",
        "    'name': 'faketest',\n",
        "    'namespace': 'test',\n",
        "    'type': 'record',\n",
        "    'fields': [\n",
        "        {'name': 'name', 'type': 'string'},\n",
        "        {'name': 'Customer', 'type': 'string'}\n",
        "    ]\n",
        "}\n",
        "\n",
        "parsed_schema = parse_schema(schema)"
      ],
      "metadata": {
        "id": "isWrII3EzTfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records = our_fake_df.to_dict('records')\n",
        "\n",
        "# 3. Write to Avro file\n",
        "with open('random_letters_compression_csv.avro', 'wb') as out:\n",
        "    writer(out, parsed_schema, records)"
      ],
      "metadata": {
        "id": "Bh05Jcqm2bzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compression_schema = {\n",
        "  'doc': 'fake test',\n",
        "  'name': 'faketest',\n",
        "  'namespace': 'test',\n",
        "  'type': 'record',\n",
        "  'fields' : [\n",
        "  {\"name\" : \"name\", 'type' : 'string'},\n",
        "  {\"name\" : \"age\", 'type' : 'int'},\n",
        "  {\"name\" : \"street\", 'type' : 'string'},\n",
        "  {\"name\" : \"zip\", 'type' : 'string'},\n",
        "  {\"name\" : \"lng\", 'type' : 'float'},\n",
        "  {\"name\" : \"lat\", 'type' : 'float'}\n",
        "  ]}\n",
        "\n",
        "parsed_comp_schema = parse_schema(compression_schema)\n",
        "\n",
        "records = our_fake_df.to_dict('records')\n",
        "\n",
        "# 3. Write to Avro file\n",
        "with open('compression_avro.avro', 'wb') as out:\n",
        "    writer(out, parsed_schema, records)"
      ],
      "metadata": {
        "id": "Srk1edWwdCyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "metadata": {
        "id": "08xEp7Fi2wem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problems with files\n",
        "\n",
        "It is possible to have data in files that is problematic. Imagine a price column with words in it or more commas than there are columns"
      ],
      "metadata": {
        "id": "EEgcyq3vppJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"Price,Customer\" > \"problem.csv\"\n",
        "!echo \"23.45,\" >> \"problem.csv\"\n",
        "!echo \"14.64\" >> \"problem.csv\"\n",
        "!echo \"Ooops!,,\" >> \"problem.csv\"\n",
        "!echo \"48.87,,,\" >> \"problem.csv\"\n",
        "\n",
        "!cat problem.csv"
      ],
      "metadata": {
        "id": "2A43KF_8p6jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem_df = pd.read_csv('problem.csv')\n",
        "problem_df"
      ],
      "metadata": {
        "id": "LoO3icuJqJB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem_df.info()"
      ],
      "metadata": {
        "id": "XBTGtEqsqOxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IcCkXCGAqb88"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}