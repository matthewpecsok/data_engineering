{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewpecsok/data_engineering/blob/main/tutorials/de_streaming_kafka_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgCc3gXybsA"
      },
      "source": [
        "### Install the required kafka packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/MyDrive/Colab Notebooks/data_engineering'"
      ],
      "metadata": {
        "id": "hqVQXFpIqibh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "48B9eAMMhAgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8bb2702-dd12-44ca-c553-c960a84fa26c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kafka-python\n",
            "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/246.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m194.6/246.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kafka-python\n",
            "Successfully installed kafka-python-2.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install kafka-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjrZNJQRJP-U"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m6KXZuTBWgRm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import time\n",
        "import threading\n",
        "import json\n",
        "from kafka import KafkaProducer\n",
        "from kafka.errors import KafkaError\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZmI7l_GykcW"
      },
      "source": [
        "## Download and setup Kafka and Zookeeper instances\n",
        "\n",
        "For demo purposes, the following instances are setup locally:\n",
        "\n",
        "- Kafka (Brokers: 127.0.0.1:9092)\n",
        "- Zookeeper (Node: 127.0.0.1:2181)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YUj0878jPyz7"
      },
      "outputs": [],
      "source": [
        "!curl -sSOL https://downloads.apache.org/kafka/3.7.0/kafka_2.12-3.7.0.tgz\n",
        "!tar -xzf kafka_2.12-3.7.0.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAzfu_WiEs4F"
      },
      "source": [
        "Kafka with defaults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n9ujlunrWgRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "028139b5-3aff-4b21-bf32-a52a8b585844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give the processes 10 seconds to start before proceeding.\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.12-3.7.0/bin/zookeeper-server-start.sh -daemon ./kafka_2.12-3.7.0/config/zookeeper.properties\n",
        "!./kafka_2.12-3.7.0/bin/kafka-server-start.sh -daemon ./kafka_2.12-3.7.0/config/server.properties\n",
        "!echo \"Give the processes 10 seconds to start before proceeding.\"\n",
        "!sleep 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6qxCdypE1DD"
      },
      "source": [
        "Is Kafka running?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "48LqMJ1BEHm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e732d2-9e8b-4020-a7e8-5cd0766fcd37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        6474       1  1 22:14 ?        00:00:02 java -Xmx512M -Xms512M -server -XX:+UseG1GC -XX:\n",
            "root        6884       1  5 22:14 ?        00:00:09 java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxG\n",
            "root        7658    5951  0 22:17 ?        00:00:00 /bin/bash -c ps -ef | grep java\n",
            "root        7660    7658  0 22:17 ?        00:00:00 grep java\n"
          ]
        }
      ],
      "source": [
        "!ps -ef | grep java"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3TntBqanQnh"
      },
      "source": [
        "Create the kafka topics with the following specs:\n",
        "\n",
        "- sample-streaming-data: partitions=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lXJWqMmWnPyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e331d432-451b-4aab-bca2-ec3724ec0413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic sample-streaming-data.\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.12-3.7.0/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 --topic sample-streaming-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNxf_NqjnycC"
      },
      "source": [
        "Describe the topic for details on the configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "apCf9pfVnwn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324d42ed-88af-41f1-e8c0-e8605a601430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: sample-streaming-data\tTopicId: GOJvkxByQXKihHS9m94DQQ\tPartitionCount: 1\tReplicationFactor: 1\tConfigs: \n",
            "\tTopic: sample-streaming-data\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.12-3.7.0/bin/kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic sample-streaming-data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generator python script"
      ],
      "metadata": {
        "id": "eD6MgELGdYrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile generator.py\n",
        "\n",
        "import sys\n",
        "args = sys.argv  # a list of the arguments provided (str)\n",
        "print(\"running generator.py\", args)\n",
        "iterations = int(args[1])\n",
        "print(f'iterations: {iterations}')\n",
        "\n",
        "def error_callback(exc):\n",
        "    raise Exception('Error while sendig data to kafka: {0}'.format(str(exc)))\n",
        "\n",
        "def write_to_kafka(topic_name, items):\n",
        "  from kafka import KafkaProducer\n",
        "\n",
        "  count=0\n",
        "  producer = KafkaProducer(bootstrap_servers=['127.0.0.1:9092'])\n",
        "  for message, key in items:\n",
        "    producer.send(topic_name, key=key.encode('utf-8'), value=message.encode('utf-8'), partition=0).add_errback(error_callback)\n",
        "    count+=1\n",
        "  producer.flush()\n",
        "  print(\"Wrote {0} messages into topic: {1}\".format(count, topic_name))\n",
        "\n",
        "import random\n",
        "from time import sleep\n",
        "\n",
        "def generate_data(rows=2):\n",
        "\n",
        "  for i in range(1,rows):\n",
        "\n",
        "    index_num = random.randint(0,1000000)\n",
        "    print(index_num)\n",
        "    keys = list([f'{index_num}'])\n",
        "    msg = list([f'hello world!{index_num}'])\n",
        "    data = zip(keys , msg)\n",
        "\n",
        "  return data\n",
        "\n",
        "for i in range(iterations):\n",
        "  write_to_kafka(\"sample-streaming-data\", generate_data())\n",
        "  sleep(random.randint(0,10))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXTRHjchRzQP",
        "outputId": "0c0c6e4b-eeee-469b-8eda-dfb44f8575dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# retrieve messages"
      ],
      "metadata": {
        "id": "qNigtAVzv89C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_messages(topic='sample-streaming-data',bootstrap_servers = '127.0.0.1:9092',output_path='output_path'):\n",
        "\n",
        "  from kafka import KafkaConsumer\n",
        "  from kafka.structs import TopicPartition\n",
        "  import gspread\n",
        "\n",
        "  consumer = KafkaConsumer(\n",
        "      bootstrap_servers=bootstrap_servers,\n",
        "      auto_offset_reset='earliest',\n",
        "      group_id='retrieve_last_items_group'\n",
        "      )###,enable_auto_commit=True)\n",
        "  # Read the specified partition\n",
        "  consumer.assign([TopicPartition(topic, 0)])\n",
        "\n",
        "\n",
        "\n",
        "  for msg in consumer:\n",
        "      # Open the file in write mode ('a')\n",
        "      file_path = 'steaming_data.csv'  # Replace with the desired file path\n",
        "      file = open(file_path, 'a')\n",
        "\n",
        "      print(f\"the msg: {msg.value.decode('utf-8')}\")\n",
        "        # Write content to the file\n",
        "      file.write(f\"{msg.value.decode('utf-8')}\\n\")\n",
        "      # Close the file\n",
        "      file.close()"
      ],
      "metadata": {
        "id": "gSyyabEVBWHV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# write some data"
      ],
      "metadata": {
        "id": "xslSU8wFe9uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script bash --bg\n",
        "\n",
        "python generator.py 3"
      ],
      "metadata": {
        "id": "8KuaSYrRSMTu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function for retrieve messages."
      ],
      "metadata": {
        "id": "cc6L3ezS5eny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieve_messages()"
      ],
      "metadata": {
        "id": "sRZeQuTiBWDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "af193f42-dc72-469a-9b9d-e4b79de35209"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-8a601ba845ba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretrieve_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-e6c228a11505>\u001b[0m in \u001b[0;36mretrieve_messages\u001b[0;34m(topic, bootstrap_servers, output_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconsumer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0;31m# Open the file in write mode ('a')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'steaming_data.csv'\u001b[0m  \u001b[0;31m# Replace with the desired file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kafka/consumer/group.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kafka/consumer/group.py\u001b[0m in \u001b[0;36mnext_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_generator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kafka/consumer/group.py\u001b[0m in \u001b[0;36m_message_generator_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_message_generator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0mtimeout_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consumer_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0mrecord_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_offsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0;31m# Generators are stateful, and it is possible that the tp / records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kafka/consumer/group.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_offsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_offsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kafka/consumer/group.py\u001b[0m in \u001b[0;36m_poll_once\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mtimeout_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_to_next_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m         \u001b[0;31m# after the long poll, we should check whether the group needs to rebalance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;31m# prior to returning data so that the group can stabilize faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kafka/client_async.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout_ms, future)\u001b[0m\n\u001b[1;32m    600\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# avoid negative timeouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;31m# called without the lock to avoid deadlock potential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kafka/client_async.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mstart_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0mend_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat steaming_data.csv"
      ],
      "metadata": {
        "id": "FEsm1CM2eymR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ],
      "metadata": {
        "id": "up15hKceZj07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(9092)\"))"
      ],
      "metadata": {
        "id": "R_acXExwZkJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%write_file recommender.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Sample user-item matrix\n",
        "user_item_matrix = np.array([\n",
        "    [4, 5, 0, 5, 0],\n",
        "    [5, 0, 4, 0, 3],\n",
        "    [0, 3, 0, 4, 5],\n",
        "    [4, 0, 5, 0, 4],\n",
        "    [0, 4, 0, 3, 0]\n",
        "])\n",
        "\n",
        "# Calculate item similarities using cosine similarity\n",
        "def calculate_item_similarities(matrix):\n",
        "    num_items = matrix.shape[1]\n",
        "    similarities = np.zeros((num_items, num_items))\n",
        "\n",
        "    for i in range(num_items):\n",
        "        for j in range(num_items):\n",
        "            if i != j:\n",
        "                item_i = matrix[:, i]\n",
        "                item_j = matrix[:, j]\n",
        "                similarity = np.dot(item_i, item_j) / (np.linalg.norm(item_i) * np.linalg.norm(item_j))\n",
        "                similarities[i, j] = similarity\n",
        "\n",
        "    return similarities\n",
        "\n",
        "# Generate item recommendations for a target user\n",
        "def generate_item_recommendations(user_id, matrix, similarities, top_k=3):\n",
        "    user_ratings = matrix[user_id]\n",
        "    num_items = matrix.shape[1]\n",
        "\n",
        "    item_scores = np.zeros(num_items)\n",
        "\n",
        "    for i in range(num_items):\n",
        "        if user_ratings[i] == 0:\n",
        "            item_i_similarity = similarities[i]\n",
        "            item_i_ratings = matrix[:, i]\n",
        "            item_scores[i] = np.dot(item_i_similarity, item_i_ratings) / np.sum(item_i_similarity)\n",
        "            print(item_scores)\n",
        "\n",
        "    #item_scores = #np.argsort(item_scores)[::-1][:top_k]\n",
        "    print(item_scores)\n",
        "\n",
        "    return item_scores\n",
        "\n",
        "# Calculate item similarities\n",
        "item_similarities = calculate_item_similarities(user_item_matrix)\n",
        "\n",
        "# Generate recommendations for user 2\n",
        "user_id = 4\n",
        "recommendations = generate_item_recommendations(user_id, user_item_matrix, item_similarities, top_k=6)\n",
        "\n",
        "print(f\"Recommendations for user {user_id}: {recommendations} with matrix {user_item_matrix[user_id]}\")"
      ],
      "metadata": {
        "id": "5MJg1y8IU7-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.nonzero(recommendations)"
      ],
      "metadata": {
        "id": "WHAmm4GTU99j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.take(recommendations, np.nonzero(recommendations), axis=0)"
      ],
      "metadata": {
        "id": "5fYv3anBola6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "arr1 = np.nonzero(recommendations)\n",
        "arr2 = np.take(recommendations, np.nonzero(recommendations), axis=0)"
      ],
      "metadata": {
        "id": "1TViCM2IrSVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr1inds = np.take(recommendations, np.nonzero(recommendations), axis=0).argsort()\n",
        "sorted_arr1 = arr1[arr1inds[::-1]]\n",
        "sorted_arr2 = arr2[arr1inds[::-1]]"
      ],
      "metadata": {
        "id": "qrAZiHDgudnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_arr1"
      ],
      "metadata": {
        "id": "_JhCg-3Fufef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kafka import KafkaAdminClient, KafkaProducer\n",
        "from kafka.admin import NewTopic\n",
        "\n",
        "# Kafka broker details\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "\n",
        "# Topic details\n",
        "topic_name = 'my_topic'\n",
        "num_partitions = 1\n",
        "replication_factor = 1\n",
        "\n",
        "# Create Kafka topic\n",
        "admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
        "topic = NewTopic(name=topic_name, num_partitions=num_partitions, replication_factor=replication_factor)\n",
        "admin_client.create_topics([topic])\n",
        "\n",
        "# Produce messages to Kafka topic\n",
        "producer = KafkaProducer(bootstrap_servers=bootstrap_servers)\n",
        "messages = ['Hello', 'World', 'Kafka', 'Python']\n",
        "\n",
        "for message in messages:\n",
        "    producer.send(topic_name, value=message.encode('utf-8'))\n",
        "\n",
        "# Close Kafka producer\n",
        "producer.flush()\n",
        "producer.close()"
      ],
      "metadata": {
        "id": "iDqlqcXquh9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kafka import KafkaConsumer\n",
        "\n",
        "# Kafka broker details\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "\n",
        "# Topic details\n",
        "topic_name = 'my_topic'\n",
        "\n",
        "# Kafka consumer configuration\n",
        "consumer = KafkaConsumer(\n",
        "    topic_name,\n",
        "    bootstrap_servers=bootstrap_servers,\n",
        "    group_id='my_consumer_group2',\n",
        "    auto_offset_reset='earliest',\n",
        "    #enable_auto_commit=True,\n",
        "    value_deserializer=lambda x: x.decode('utf-8')\n",
        ")\n",
        "\n",
        "# Consume and process messages from Kafka topic\n",
        "for message in consumer:\n",
        "    print(\"Received message:\", message.value)\n",
        "\n",
        "# Close Kafka consumer\n",
        "consumer.close()\n"
      ],
      "metadata": {
        "id": "tLiVNwbjz72I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yx3MecqE0NSw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}