{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNFRWEp3LvjT3yII0keJ6tk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewpecsok/data_engineering/blob/main/tutorials/de_tutorial_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction from a OLTP Source System\n",
        "\n",
        "In this tutorial we'll begin exploring the concept of querying a OLTP database, not for analytics, but rather to start extracting data for downstream data engineering applications."
      ],
      "metadata": {
        "id": "xAiVeVSSlu0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Engineering**\n",
        "\n",
        "**Matthew Pecsok 2/10/2023**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CKCSeniFldev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.&nbsp;A quick overview of lists and tuples\n",
        "\n",
        "in python a list is object that can store multiple items, is changeable, and allows duplicate values.\n",
        "\n",
        "A list can begin empty and items can be added to it."
      ],
      "metadata": {
        "id": "bGx_0RHcXUaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = [] #create an empty list\n",
        "my_list"
      ],
      "metadata": {
        "id": "uN5f7xlrXtBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_list.append('movie_1') # append a single item to the list\n",
        "my_list"
      ],
      "metadata": {
        "id": "ow25R0zNXkDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_list.extend(['movie_2','movie_3']) # concatenate two lists together creating a single list as a result\n",
        "my_list"
      ],
      "metadata": {
        "id": "sGK4V0IxXXaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(my_list) # how long is out new list?"
      ],
      "metadata": {
        "id": "11LbeMHyYkhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if we want to store immutable data? We can use a **tuple**. A tuple is similar to a list except it is ordered unchangeable, and allows duplicate values. Notice the parenthesis instead of brackets."
      ],
      "metadata": {
        "id": "7wqa2HMfYsKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_1 = ('Toy Story',1995)\n",
        "movie_1"
      ],
      "metadata": {
        "id": "A-3gK65YZJHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_2 = ('Monsters Inc.',2001)\n",
        "movie_2"
      ],
      "metadata": {
        "id": "ocU0hyi7ZWsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_complex_list = []\n",
        "my_complex_list"
      ],
      "metadata": {
        "id": "H59dMJTCYreX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_complex_list.extend([movie_1,movie_2])"
      ],
      "metadata": {
        "id": "ypC0sUpdZfCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_complex_list"
      ],
      "metadata": {
        "id": "9Mv6oMuEZj5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_complex_list[0] # get the zeroth (or first depending on how you count) element in the list"
      ],
      "metadata": {
        "id": "y43M5CsXZpHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_complex_list[0][1]"
      ],
      "metadata": {
        "id": "rdrHQOwjZquh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For loops on lists\n",
        "\n",
        "It's quite easy to loop through a list and execute some code on that list. Here's a few examples to get your comfortable.\n",
        "\n",
        "Please note, for loops are not the most efficient way to accomplish tasks like this, but they are simple to understand."
      ],
      "metadata": {
        "id": "3t-8LxH-0ySV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "\n",
        "for fruit in ['apples','oranges','bananas']:\n",
        "  print(f'the current fruit is {fruit}')\n",
        "  i += 1\n",
        "\n",
        "print(f'we looped {i} times')"
      ],
      "metadata": {
        "id": "TdnYKarZ17Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for the_number in [1,2,3,4,5,6,42]:\n",
        "  print(f'{the_number} is even = {(the_number%2==0)}')"
      ],
      "metadata": {
        "id": "ZySG_tna0xXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The takeaway here is that a for loop allows us to iterate over a list and execute code for each element in the list."
      ],
      "metadata": {
        "id": "Xva5Wh0Y3CME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.&nbsp;Package import and get database"
      ],
      "metadata": {
        "id": "arrHkjf8bcJw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1yc-iVTXDvv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qO movies.db https://github.com/matthewpecsok/data_engineering/blob/main/data/movies.sqlite?raw=true\n",
        "\n",
        "!pip -q install --upgrade ipython\n",
        "!pip -q install --upgrade ipython-sql\n",
        "\n",
        "con = sqlite3.connect('movies.db')\n",
        "\n",
        "%load_ext sql\n",
        "%sql sqlite:///movies.db\n",
        "\n",
        "%config SqlMagic.autopandas = True\n",
        "%config SqlMagic.feedback = False"
      ],
      "metadata": {
        "id": "WtfwacKRXILU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con # con is our connection to the database"
      ],
      "metadata": {
        "id": "8IRd1QFKbolu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur = con.cursor()\n",
        "cur # cursor"
      ],
      "metadata": {
        "id": "NuByQBYqexaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query('select * from movies limit 2',con)"
      ],
      "metadata": {
        "id": "Bc0jLR-auqVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = cur.execute('select * from movies').fetchall()\n",
        "len(res)"
      ],
      "metadata": {
        "id": "1-dlecVle4vM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423c974e-af99-45c1-8009-15c88b20cc72"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4773"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "release_date_range = cur.execute(\"select min(release_date),max(release_date),JULIANDAY(max(release_date))-JULIANDAY(min(release_date)) as days from movies\").fetchall()\n",
        "release_date_range"
      ],
      "metadata": {
        "id": "W353m_8VfXXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we create an extraction for each date (as we might in a daily batch system) then we will have 36677 batches. That's about 365 batches for each day of the year x 100 years of data (approx)\n",
        "\n",
        "to visualize this process let's print out just the first 4 batches"
      ],
      "metadata": {
        "id": "6y2I0Lv_m7N-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for release_date in range(0,4):\n",
        "  result = cur.execute(f\"select * from movies where release_date = date('1916-09-04','+{release_date} days')\").fetchall()\n",
        "  display(result)"
      ],
      "metadata": {
        "id": "2oJD8BEUkh37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "as you can see the first batch has data, but the next 3 do not (empty data respresented by [] <- an empty list.\n",
        "\n",
        "Let's see how long it takes to run all 36,677 batch queries.\n",
        "\n",
        "tqdm gives us a running counter for our for loop"
      ],
      "metadata": {
        "id": "bCyecV6msnvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create a simple list with one tuple for exploration using the data above."
      ],
      "metadata": {
        "id": "EpWpdPYu7s8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_list = [(48189,\n",
        "  'Intolerance',\n",
        "  385907,\n",
        "  3,\n",
        "  '1916-09-04',\n",
        "  8394751,\n",
        "  'Intolerance',\n",
        "  7.4,\n",
        "  60,\n",
        "  'The story of a poor young woman, separated by prejudice from her husband and baby, is interwoven with tales of intolerance from throughout history.',\n",
        "  'The Cruel Hand of Intolerance',\n",
        "  3059,\n",
        "  6968)]\n",
        "\n",
        "movie_list[0][1] # the first movie in the list and second column"
      ],
      "metadata": {
        "id": "5ufnjCgswm7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for release_date_int in tqdm.tqdm(range(0,36678)):\n",
        "  batch = cur.execute(f\"select * from movies where release_date = date('1916-09-04','+{release_date_int} days')\").fetchall()\n",
        "  #print(f' batch for {release_date_int} with size {len(batch)}')"
      ],
      "metadata": {
        "id": "XZQOAj2TOIoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will simulate a daily pull by writing a simple for loop and processing all of the movies for each date. In a real system you can imagine this process kicks off each day using the previous day's date to extract all of the movies entered each day.\n",
        "\n",
        "The extraction appears to take about a minute or so.\n",
        "\n",
        "**Of course, we haven't moved the data anywhere yet so that will take additional time.**\n",
        "\n",
        "Let's create a new database with a NEW table that just has the batch number and the movie title as we migrate the data from the existing to this new table.\n",
        "\n",
        "This NEW database is EMPTY (for now)"
      ],
      "metadata": {
        "id": "iIqe_a9Bn0N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "con_migrate = sqlite3.connect('movies_migrated.db')\n",
        "cur_migrate = con_migrate.cursor()"
      ],
      "metadata": {
        "id": "DC4MMuodvaRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur_migrate.execute(\"drop table if exists movie_migration\").fetchall()\n",
        "cur_migrate.execute(\"create table movie_migration(batch_id INT,movie_title TEXT)\").fetchall()"
      ],
      "metadata": {
        "id": "e2vojVujn0jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "whenever you are about to run something 36678 times, start with just a few rows to make sure it works as expected."
      ],
      "metadata": {
        "id": "EARCyur8y1Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for release_date_int in tqdm.tqdm(range(0,3)):\n",
        "  batch = cur.execute(f\"select title from movies where release_date = date('1916-09-04','+{release_date_int} days')\").fetchall()\n",
        "  for i in range(len(batch)): # there may be multiple movies for a given release date, loop for each\n",
        "    display(batch[i])\n",
        "    cur_migrate.execute(f\"insert into movie_migration (batch_id,movie_title) values ({release_date_int},'{batch[i][0]}')\")"
      ],
      "metadata": {
        "id": "-YQAhlUJnzY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query('select * from movie_migration',con_migrate)"
      ],
      "metadata": {
        "id": "zfbPEgQgyDpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! It worked and inserted the one movie we expected and didn't seem to create any other rows we wouldn't have wanted.\n",
        "\n",
        "Next let's clean the table up and get rid of the rows before re-running."
      ],
      "metadata": {
        "id": "VidtZvSQzAjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_migrate.execute(f\"delete from movie_migration\")\n",
        "cur_migrate.execute(f\"select count(1) from movie_migration\").fetchall()"
      ],
      "metadata": {
        "id": "vK4bAo61zLOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now run it for ALL records.\n",
        "\n",
        "This process creates an insert statement for EACH DAY. Each batch is then extremely small (often zero records)."
      ],
      "metadata": {
        "id": "NlNh3zpc7BAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# all records in one batch"
      ],
      "metadata": {
        "id": "dVgkNvnONoLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_migrate.execute(f\"delete from movie_migration\")\n",
        "batch = cur.execute(f\"select 1,title from movies\").fetchall()\n",
        "cur_migrate.executemany(f\"insert into movie_migration (batch_id,movie_title) values (?,?)\",batch)\n",
        "cur.execute(f\"select count(1) from movies\").fetchall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyagwL8KNqLj",
        "outputId": "21f8c65e-6f99-4aa0-e249-1a84a9e5190b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4773,)]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.&nbsp;Small batch insert"
      ],
      "metadata": {
        "id": "2_8t3oXujt1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for release_date_int in tqdm.tqdm(range(0,36678)):\n",
        "  batch = cur.execute(f\"select title from movies where release_date = date('1916-09-04','+{release_date_int} days')\").fetchall()\n",
        "  for i in range(len(batch)):\n",
        "    # display(batch[i]) uncomment this to see the tuple of movies that are being inserted\n",
        "    cur_migrate.execute(f\"\"\"insert into movie_migration (batch_id,movie_title) values ({release_date_int},\"{batch[i][0]}\")\"\"\")"
      ],
      "metadata": {
        "id": "tdg7gkixzv2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102c1409-88f1-4ed9-b100-8e5ba6665772"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36678/36678 [00:47<00:00, 775.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That took a little over a minute to run. Let's check out our new database and table"
      ],
      "metadata": {
        "id": "zUe-XIXsOn12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query('select * from movie_migration limit 8',con_migrate)"
      ],
      "metadata": {
        "id": "J2Z9LUJ4OXha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query('select count(1) from movie_migration',con_migrate)"
      ],
      "metadata": {
        "id": "hGHDo0f12TAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query('select count(1) from movies',con)"
      ],
      "metadata": {
        "id": "MIgYI4y62dmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.&nbsp;Large batch insert\n",
        "\n",
        "Create batches by YEAR instead of by day. This greatly increases the batch size. When we processed by day we had over 36,000 batches, many with 0 records. With year we should have only 100 or so batches with many more records in each batch.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g1onZpGMc0_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   By Year\n",
        "\n"
      ],
      "metadata": {
        "id": "PwOIT6u9cSdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql select\n",
        "\n",
        "round(avg(count),1) as avg_yearly_release_count,\n",
        "avg(count) as avg_release_count\n",
        "\n",
        "from (\n",
        "  select count(1) as count from movies group by strftime('%Y',release_date)\n",
        "  ) as count"
      ],
      "metadata": {
        "id": "3ll9DTTpa9Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   By Date (day)\n",
        "\n"
      ],
      "metadata": {
        "id": "Np5ksRlWcVP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql select\n",
        "round(avg(count),1) as avg_daily_release_count,\n",
        "avg(count) as avg_release_count\n",
        "\n",
        "from (\n",
        "  select count(1) as count from movies group by release_date\n",
        "  ) as count"
      ],
      "metadata": {
        "id": "pjoVbu_lbtie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the average number of movies released each year is 53.\n",
        "\n",
        "The table below attempts to show the tradeoffs between larger and smaller batches.\n",
        "\n",
        "Batch Type | Batch Count | Avg Movies per Batch | Pro | Con\n",
        "--|--|--- | ---| ---\n",
        "by Day | 36,000  | 1.5 | low memory batches | many batches\n",
        "by Year | 100  | 53 | higher memory batches | fewer batches\n"
      ],
      "metadata": {
        "id": "YoUl-Tr9bSac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_migrate.execute(f\"delete from movie_migration\")\n",
        "cur_migrate.execute(f\"select count(1) from movie_migration\").fetchall()"
      ],
      "metadata": {
        "id": "SKYUnbpL2g9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql select\n",
        "min(strftime('%Y',release_date)) as first_year,\n",
        "max(strftime('%Y',release_date)) as last_year,\n",
        "\n",
        "cast(max(strftime('%Y',release_date)) as int) - cast(min(strftime('%Y',release_date)) as int) as total_years\n",
        " from movies"
      ],
      "metadata": {
        "id": "v9bxRnohdSK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for release_year_int in tqdm.tqdm(range(1916,2018)):\n",
        "  batch = cur.execute(f\"select {release_year_int},title from movies where strftime('%Y',release_date) = cast({release_year_int} as str)\").fetchall()\n",
        "  cur_migrate.executemany(f\"insert into movie_migration (batch_id,movie_title) values (?,?)\",batch)\n",
        "\n",
        "con_migrate.commit()"
      ],
      "metadata": {
        "id": "0v7teQ7_dLzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this new batch mode went from 45 seconds to less than a second to insert all the records."
      ],
      "metadata": {
        "id": "FGaQYbgdgfNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query(\"select count(1) from movie_migration\",con_migrate)"
      ],
      "metadata": {
        "id": "3fZqrD_wfs-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query(\"select * from movie_migration order by batch_id desc limit 10\",con_migrate)"
      ],
      "metadata": {
        "id": "c89j3gIUAzgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.&nbsp;Fixed size batch insert\n",
        "\n",
        "Create batches by a specific number of rows. We then have a specific batch size each time (except for the last batch). In this way we create a specific payload size for each batch rather than a variable size as shown in the previous examples.\n"
      ],
      "metadata": {
        "id": "Kp5-KZ2XCDlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_migrate.execute(f\"delete from movie_migration\")\n",
        "cur_migrate.execute(f\"select count(1) from movie_migration\").fetchall()"
      ],
      "metadata": {
        "id": "w1fVQ7WbCY8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur.execute(f\"select count(1) from movies\").fetchall()"
      ],
      "metadata": {
        "id": "gebtNBUwDWdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4773 movies. in batches of 1000 that should be 5 batches."
      ],
      "metadata": {
        "id": "fbLTVdL0DYve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur.execute(f\"select cast(cast(count(1) as float)/1000 as float) from movies\").fetchall()"
      ],
      "metadata": {
        "id": "BecjaL_PC4GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_batch = [0, 1000, 2000, 3000, 4000]\n",
        "fixed_batch"
      ],
      "metadata": {
        "id": "EeKHXyzcDiSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we take advantage of the limit and offset parameters in sql to create batches of fixed size (1000 rows) in each batch.\n",
        "\n",
        "Fixed batch sizes allows for predictable payload and memory requirements.\n",
        "\n",
        "**LIMIT** forces a specific number of rows to be returned.\n",
        "\n",
        "**OFFSET** sets the number of rows to skip.\n",
        "\n",
        "By keeping limit fixed and increasing OFFSET we can pull\n",
        "\n",
        "row range| batch | OFFSET | LIMIT\n",
        "--|--| -- | --\n",
        "1-1000 | (batch 1) | 0 | 1000\n",
        "1001-2000 | (batch 2) | 1000 | 1000\n",
        "2001-3000 | (batch 3) | 2000 | 1000\n",
        "3001-4000 | (batch 4) | 3000 | 1000\n",
        "4001-5000  | (batch 5) | 4000  | 1000\n"
      ],
      "metadata": {
        "id": "bgCu743OHQqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in tqdm.tqdm(fixed_batch):\n",
        "  batch = cur.execute(f\"select {batch},title from movies LIMIT 1000 OFFSET {batch}\").fetchall()\n",
        "  cur_migrate.executemany(f\"insert into movie_migration (batch_id,movie_title) values (?,?)\",batch)\n",
        "\n",
        "con_migrate.commit()"
      ],
      "metadata": {
        "id": "s7p0sq7SCCrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query(\"select count(1),batch_id from movie_migration group by batch_id\",con_migrate)"
      ],
      "metadata": {
        "id": "ZN017ji9EvAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql select\n",
        "count(1),batch_id from movie_migration group by batch_id"
      ],
      "metadata": {
        "id": "UtEjKEWJEjUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.&nbsp;Conclusion\n",
        "\n",
        "Moving data between two databases means that we need to break our data up into groups of rows aka batches. Trying to do one enormous batch would generally overwhelm our system resources.\n",
        "\n",
        "* **Small Batches**: By choosing many small batches we reduce memory requirements for each batch, but we increase the number of batches which if latency is a concern may be a problem.\n",
        "\n",
        "*  **Large Batches**: By choosing large batches we increase memory requirements for each batch, but we decrease the total number of trips to the database which can reduce the impact of latency.\n",
        "\n",
        "* **Fixed Batches**: can force a specific number of rows into the payload. This can help create a standardized data pull for each batch rather than a variable size as the previous two example showed."
      ],
      "metadata": {
        "id": "hm9WvbjNgwEO"
      }
    }
  ]
}